---
title: "R03_5_PTT_scraping_cookie"
author: "B06208001 龔泓愷"
date: "2019/10/18"
output:
  html_document:
    highlight: zenburn
    number_sections: yes
    theme: cerulean
    toc: yes
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# loading packages
```{r library, message=FALSE, warning=FALSE}
library(rvest)
library(httr)
library(tidyverse)
options(stringsAsFactors = F)
```

# GET() html with cookie

## Testing: GET() directly
```{r}
# url
url <- "https://www.ptt.cc/bbs/HatePolitics/index.html"

# Using read_html(), write_html() and browseURL() to examine the link
read_html(url) %>% write_html("test.html")

# Browsing the URL by browseURL()
browseURL("test.html")
```

## Testing: GET() with cookie
```{r}
# GET html with cookie
url <- "https://www.ptt.cc/bbs/HatePolitics/index.html"
response <- GET(url, config = set_cookies("over18" = "1"))

# content() %>% read_html() to an xml_document
response %>%
  content("text") %>%
  read_html() %>%
  write_html("test_with_cookies.html")

# Examining the url
browseURL("test_with_cookies.html")
```

## Code: GET() html with cookie
```{r}
# the url
url <- "https://www.ptt.cc/bbs/HatePolitics/index.html"

# GET() with cookie and convert to xml_document by read_html()
doc <- GET(url, config = set_cookies("over18" = "1")) %>%
  content("text") %>%
  read_html()

# write_html() again to final checking
doc %>% write_html("test_with_cookies.html")
```

# Parse html

```{r}
# GET() all nodes
nodes <- html_nodes(doc, ".r-ent")
length(nodes)

# For all nodes, retrieve number of recommendation to var nrec
nrec <- html_node(nodes, ".nrec span") %>% html_text() %>% as.numeric()
nrec

# For all nodes, retrieve title to variable title
title <- html_node(nodes, ".title a") %>% html_text()
title

# For all nodes, retrieve link to variable link
# Remember to paste the prefix link to the link
# Try to browse it for verification
pre <- "https://www.ppt.cc"

link <- html_node(nodes, ".title a") %>% 
  html_attr("href") %>%
  str_c(pre, .)
link

# For all nodes, retrieve author to variable author
author <- html_nodes(nodes, ".meta .author") %>% html_text()
author

# Combine all variable as data.frame
page.df <- data.frame(nrec, title, link, author)
```

# Formatting the url
```{r}
url <- "https://www.ptt.cc/bbs/HatePolitics/search?page=1&q=林昶佐"

# the query -> query
query <- "林昶佐"

# the prefixed url -> pre
pre <- "https://www.ptt.cc"

# the url by pasting the url, page number and the query
url <- str_c("https://www.ptt.cc/bbs/HatePolitics/search?page=",
             1,
             "&q=",
             query)

# preview the url
url
```

# Using for-loop to get back all pages
```{r warning=FALSE}
Sys.setlocale(category = "LC_ALL", locale = "cht")

# the query
query <- "林昶佐"
pre <- "https://www.ptt.cc"

# Creating an empty data frame by data_frame()
post.df <- data.frame()

# for-loop
for (page in c(1:8)) {
  url <- str_c("https://www.ptt.cc/bbs/HatePolitics/search?page=",
             page,
             "&q=",
             query)
  print(url)
  
  doc <- GET(url, config = set_cookies("over18" = "1")) %>%
    content("text") %>%
    read_html()
  nodes <- html_nodes(doc, ".r-ent")
  Sys.setlocale(category = "LC_ALL", locale = "Chinese") # 莫名其妙的轉換才能在page = 8跑as.numeric()
  nrec <- html_node(nodes, ".nrec span") %>% html_text() %>% as.numeric()
  title <- html_node(nodes, ".title a") %>% html_text()
  link <- html_node(nodes, ".title a") %>% 
    html_attr("href") %>%
    str_c(pre, .)
  author <- html_nodes(nodes, ".meta .author") %>% html_text()
  
  page.df <- data.frame(nrec, title, link, author)
  
  post.df <- rbind(post.df, page.df)
  message(nrow(post.df))
} 

post.df %>% write_rds("post_HatePolitics_lin.rds")
```

# NOTES and FURTHER
Now we detect the last page number manually. You can try to write a function to crawl back all data given a board name and a query. One more thing you need to think by yourself is that you need to detect the last page number automatically. Try to do it!

```{r}
# Def function to find the last page
find_end_page <- function(ptt, query) {
  page = 1
  status = TRUE
  while (status == TRUE) {
    url <- str_c("https://www.ptt.cc/bbs/", ptt, "/search?page=", page, "&q=", query)
    doc <- GET(url) %>% content("text") %>% read_html()
    content <- html_node(doc, ".bbs-content") %>% html_text
    
    if (content != "404 - Not Found.") {
      status = FALSE
    }
    
    page = page + 1
  }
  return(page)
}

# the query
query <- "Pixel4"
pre <- "https://www.ptt.cc"
end <- find_end_page("MobileComm", query)

# Creating an empty data frame by data_frame()
post.df <- data.frame()

# for-loop
for (page in c(1:end)) {
  url <- str_c("https://www.ptt.cc/bbs/MobileComm/search?page=",
             page,
             "&q=",
             query)
  print(url)
  
  doc <- GET(url, config = set_cookies("over18" = "1")) %>%
    content("text") %>%
    read_html()
  nodes <- html_nodes(doc, ".r-ent")
  nrec <- html_node(nodes, ".nrec span") %>% html_text() %>% as.numeric()
  title <- html_node(nodes, ".title a") %>% html_text()
  link <- html_node(nodes, ".title a") %>% 
    html_attr("href") %>%
    str_c(pre, .)
  author <- html_nodes(nodes, ".meta .author") %>% html_text()
  
  page.df <- data.frame(nrec, title, link, author)
  
  post.df <- rbind(post.df, page.df)
  message(nrow(post.df))
} 

post.df %>% write_rds("post_Mobile_p4.rds")
head(post.df)
```

